{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "<img src=\"images/python-logo.jpg\" alt=\"Python\" style=\"width: 300px;\"/>\n",
    "\n",
    "O Pandas (https://pandas.pydata.org/) é uma library para análise e manipulação de dados. É uma das ferramentas mais utilizadas por Data Scientists devido à sua flexibilidade e às diversa gama de funcionalidades que oferece. Permite, entre outras coisas:\n",
    "\n",
    "* carregar dados de várias fontes e tipos de ficheiros diferentes;\n",
    "* descrever estatisticamente um conjunto de dados;\n",
    "* fazer a limpeza dos dados;\n",
    "* fazer cálculos mais complexos sobre os dados: calcular \"rolling averages\" (valores médios ao longo do tempo), agrupar dados e calcular métricas dentro de cada conjunto, agregar dados de fontes diferentes;\n",
    "* exportar dados para vários formatos.\n",
    "\n",
    "Neste notebook vamos explorar várias destas funcionalidades através de um exemplo prático, que nos permitirá passar por cada um destes pontos da \"pipeline\" de processamento de dados. Depois iremos complementar este conhecimento com algumas técnicas mais avançadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas - definições essenciais\n",
    "\n",
    "O Pandas assenta sobre duas estruturas de dados particulares: as Series e as DataFrames.\n",
    "\n",
    "Podemos pensar nestas estruturas como colunas e tabelas: uma DataFrame é semelhante a uma tabela, e cada uma das suas colunas é uma Series. Estas estruturas podem conter vários tipos de dados diferentes, e permitem efectuar vários tipos de operações diferentes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series\n",
    "\n",
    "Vamos começar por importar o Pandas e construir uma Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos criar uma Series com base numa lista:\n",
    "dados = [35, 42, 55.0, 67]\n",
    "\n",
    "series_ex = pd.Series(dados)\n",
    "\n",
    "series_ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma série é muito semelhante a uma lista. Contém:\n",
    "\n",
    "* um índice que identifica cada elemento.\n",
    "* valores (que podem ser de vários tipos)\n",
    "\n",
    "`dtype` refere-se ao tipo de dados contidos na série. Estes tipos de dados têm um certo grau correspondência com os tipos básicos de variáveis de Python (podemos ver que esta série é do tipo int64, um tipo de dados usado para representar números inteiros). Há algumas diferenças, por exemplo: o dtype `object` é usado quando temos uma série de strings, uma série números e strings, e para alguns outros tipos de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A principal diferença entre uma série e uma lista é que o índice de uma série pode ter valores diferentes, não tendo necessariamente de ser 0, 1, 2, ... \n",
    "Uma série pode também ter um nome.\n",
    "\n",
    "Vejamos como podemos criar uma série com um índice diferente, e com um nome:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = ['C35', 'D12', 'H54', 'X17']\n",
    "indice = ['segunda', 'terça', 'quarta', 'quinta']\n",
    "\n",
    "series_ex = pd.Series(\n",
    "    data=dados,\n",
    "    index=indice,\n",
    "    name='códigos_diários'\n",
    ")\n",
    "\n",
    "series_ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma série é semelhante a um dicionário na maneira de aceder aos seus valores: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_ex['segunda']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível criar uma série a partir de um dicionário:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicionario = {\n",
    "    'indice_1': 'valor_1',\n",
    "    'indice_2': 'valor_2'\n",
    "}\n",
    "\n",
    "serie = pd.Series(dicionario)\n",
    "\n",
    "serie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame\n",
    "\n",
    "Uma DataFrame é essencialmente uma tabela em que cada coluna é uma Series. É possível criar DataFrames a partir de vários iteráveis diferentes como listas, dicionários e séries.\n",
    "\n",
    "A maneira mais prática de o fazer é usando um dicionário em que o nome de cada coluna é dado pelas chaves do dicionário, e os valores de cada coluna são dados pelos valores do dicionário:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = {\n",
    "    'nomes': ['Fred', 'João', 'Maria'],\n",
    "    'idades': [26, 27, 28],\n",
    "    'profissão': ['Data Scientist', 'Biologist', 'Software Engineer']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(dados)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A maior parte do processamento de dados em Python pode ser feito usando o Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science / Analysis com o Pandas\n",
    "\n",
    "Devido ao grande número de operações possíveis que podem ser executadas com o Pandas, não seria uma boa abordagem listá-las uma a uma num único notebook. Em vez disso, vamos ver um exemplo de uma tarefa que um Data Scientist poderia ter que realizar no seu dia-a-dia, e a cada passo do caminho serão discutidas as funções mais relevantes.\n",
    "\n",
    "Vamos entrar no \"mindset\" de um Data Scientist!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa: análise de reviews de hotéis\n",
    "\n",
    "Imaginem que são um Data Scientist a trabalhar para uma agência de viagens, e vos é pedido que analizem em que regiões os hotéis são em média mais bem classificados, de modo a que a que a empresa possa fazer campanhas publicitárias direccionadas a essas áreas. Para além disso são livres de apresentar quaisquer outras conclusões ou detalhes interessantes que encontrem nos dados.\n",
    "\n",
    "Foi-vos fornecido um conjuntos de dados (na pasta `data/hotel-reviews`):\n",
    "\n",
    "* hotel_reviews.csv contém classificações dadas por utilizadores a vários hotéis e outros estabelecimentos;\n",
    "* postal_codes.csv contém o código postal e província de cada hotel.\n",
    "\n",
    "Vamos ver, passo a passo, uma possível maneira de abordar este problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura dos dados\n",
    "\n",
    "Vamos começar por ler os dados. Podemos ver que os dados estão no formato .csv (\"comma-separated values\"). Para importar os dados para o nosso Notebook, podemos servir-nos da função **read_csv** dos Pandas, que irá ler os dados para uma DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/hotel-reviews/hotel_reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O pandas fornece várias funções do tipo **read_*extensão*** que nos permitem importar ficheiros de vários formatos diferentes. Estas funções também têm vários aergumentos opcionais para lidar com headers, dar outros nomes às colunas, etc.\n",
    "\n",
    "O melhor a fazer quando queremos importar um ficheiro com um formato pouco convencional (por exemplo, 2 linhas de headers) será consultar a documentação e procurar uma solução para o nosso caso em particular - é muito provável que a solução já exista e seja simples, dada a importância do passo de leitura do dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise inicial\n",
    "\n",
    "Após carregarmos os dados, o primeiro passo será fazer uma análise inicial, só para começar a formar uma imagem mental do conjunto de dados. É muito importante familiarizarmo-nos com os dados, pois isto desbloqueia novas ideias que podemos explorar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver as primeiras linhas de uma dataframe, podemos usar o método **head**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O mesmo se aplica para as ultimas linhas, com o método **tail**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver o formato da nossa DataFrame através da sua **shape**.\n",
    "\n",
    "Atenção: shape não é um método, mas sim um atributo! Ou seja, é uma propriedade de cada DataFrame a que podemos aceder da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que o atributo **shape** é um tuplo. O primeiro valor dá-nos o número de linhas (10000), e o segundo valor dá-nos o número de colunas (23) da nossa DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver o tipo de dados que cada coluna contém com o atributo **dtypes**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E o nome das colunas com o atributo **columns**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Pandas fornece também dois métodos muito úteis para descrever uma DataFrame de forma geral. O primeiro é o método **info**. Este método dá-nos a shape, os dtypes, e o número de valores não nulos de uma DataFrame, entre outras informações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O segundo método, ainda mais útil, é o método **describe**. Este método devolve uma DataFrame com uma descrição estatística das colunas numéricas da DataFrame original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos, para cada coluna numérica:\n",
    "\n",
    "* a contagem de valores por coluna;\n",
    "* o valor médio, mínimo, máximo e o desvio padrão;\n",
    "* os percentis 25%, 50% e 75% (podemos ter outros através do argumento percentiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aceder aos valores da DataFrame (\"slicing\")\n",
    "\n",
    "Agora que já conseguimos uma visão geral sobre os dados, vamos aprender extrair os valores que desejamos da DataFrame.\n",
    "\n",
    "Podemos aceder a conjuntos de valores de uma DataFrame especificando os índices e as colunas que desejamos. A melhor maneira de o fazermos é através do oparedor **loc**, que tem a seguinte sintaxe:\n",
    "\n",
    "    df.loc[valores_do_indice, valores_das_colunas]\n",
    "    \n",
    "Podemos também usar o operador **iloc** se quisermos referir-nos ao índice e as colunas pelo seu número, e não pelo seu nome:\n",
    "\n",
    "    df.iloc[numero_da_linha, numero_da_coluna]\n",
    "\n",
    "Vamos começar por extrair a primeira linha da DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primeira_linha = df.loc[0]\n",
    "\n",
    "primeira_linha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que esta operação retorna uma Series ou seja: as linhas de uma DataFrame são também tratadas como Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(primeira_linha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora seleccionar o rating da 3ª linha da DataFrame. Podemos ver, olhando para as colunas da DataFrame, que a coluna de interesse é **reviews.rating**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[3, 'reviews.rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um rating bastante baixo! Podemos aceder a coluna **reviews_rating** como se estivessemos a aceder a um valor de um dicionário:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviews.rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sempre que quisermos aceder a mais do que uma coluna, devemos passar uma lista de nomes de colunas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[3, ['name', 'reviews.rating']]  # uma única linha: obtemos uma série."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['name', 'reviews.rating']]  # múltiplas colunas: obtemos uma DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos aceder a uma coluna individualmente através da **dot notation** ( . ), se esta coluna não tiver pontos ou espaços no seu nome:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing avançado\n",
    "\n",
    "Para além de aceder a valores, colunas ou linhas individualmente, podemos seleccionar conjuntos de dados com base em condições.\n",
    "\n",
    "Por exemplo, vamos tentar seleccionar o subconjunto da nossa DataFrame que contenha as piores classificações (1 estrela). Podemos aplicar um operador condicional sobre uma coluna, e o resultado será, **linha a linha**, se cada valor cumpre essa condição:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviews.rating'] == 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que esta opeação condicional nos devolveu uma **Series** com valores booleanos: True se uma determinada linha tinha classificação de 1 estrela, False caso contrário.\n",
    "\n",
    "Operações de slicing mais complexas são possíveis devido à seguinte propriedade:\n",
    "\n",
    "- **É possível usar uma Série Booleana para seleccionar linhas de uma DataFrame**\n",
    "\n",
    "Desta forma, se usarmos **loc** em conjunto com a série que obtivemos anteriormente, vamos seleccionar **todas as linhas para as quais a condição é verdadeira**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mas_reviews = df.loc[\n",
    "    (df['reviews.rating'] == 1.0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mas_reviews.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mas_reviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos aplicar condições utilizando várias colunas simultaneamente, seguindo uma lógica de **and/or**.\n",
    "Há algumas diferenças, devido ao facto destas comparações serem feitas linha-a-linha:\n",
    "\n",
    "* o \"and\" é substituído pelo operador **&** \n",
    "* o \"or\" é substituído pelo operador **|** \n",
    "* o \"not\" é substituído pelo operador **~**\n",
    "* as condições devem estar individualmente entre parêntesis\n",
    "\n",
    "Vejamos agora classificações de 5 estrelas para hotéis em Nova Iorque, e selecionar apenas o seu nome e o username do utilizador que deixou a review: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boas_reviews_em_NY = df.loc[\n",
    "    (df[\"reviews.rating\"] == 5.0) &\n",
    "    (df[\"city\"] == \"New York\"),\n",
    "    ['name', 'reviews.username']\n",
    "]\n",
    "\n",
    "boas_reviews_em_NY.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos modificar valores numa DataFrame de forma bastante intuitiva. Imaginemos que fomos informados que a review do utilizador *Laurel D* para o *Pearl Hotel* estava errada - na verdade devia ser 1 estrela. Podemos corrigir os dados da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\n",
    "    (df['reviews.username'] == 'Laurel D') &\n",
    "    (df['name'] == 'The Pearl Hotel'),\n",
    "    'reviews.rating'\n",
    "] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.loc[\n",
    "    (df['reviews.username'] == 'Laurel D') &\n",
    "    (df['name'] == 'The Pearl Hotel')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ver mais duas técnicas para seleccionar valor: **mask** e **where**.\n",
    "\n",
    "Os métodos **mask**/**where** devolvem uma DataFrame onde os valore que cumprem/não cumprem uma determinada condição ficam escondidos, sendo substituido por **NaN** (\"not-a-number\", o equivalente a None do Pandas). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mask(df.city == 'Rancho Santa Fe').head()  # as primeiras três rows eram desta cidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(df.city == 'Rancho Santa Fe').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As operações de slicing são essenciais para o uso do Pandas, pois permitem-nos seleccionar exatamente o conjunto de dados que pretendemos analisar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operações sobre Series\n",
    "\n",
    "As Series permitem um número elevado de operações muito úteis na análise de dados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação de novas colunas\n",
    "\n",
    "Podemos criar novas colunas das seguinte formas:\n",
    "\n",
    "* atribuindo uma Series a esta coluna; o matching será feito entre o índice da Series, e o índice da DataFrame (e as linhas da DataFrame que não tiverem um elemento correspondente na Series ficarão com o valor NaN);\n",
    "* atribuindo o mesmo valor a todos os elementos da coluna;\n",
    "* construindo uma nova coluna a partir de colunas existente.\n",
    "\n",
    "Das três opções, a última costuma ser a mais comum em análise de dados. Vejamos como podemos criar uma coluna **country_city** que seja a concatenação do país e da cidade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['country_city'] = df['country'] + ', ' + df['city']\n",
    "\n",
    "df['country_city']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Series suportam várias operações elemento-a-elemento entre si, como a soma ou a multiplicação. Os elementos são alinhados entre as duas séries pelo seu índice. \n",
    "\n",
    "Agora vamos criar uma coluna com o rating multiplicado por 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['rating_0_to_50'] = df['reviews.rating'] * 10\n",
    "\n",
    "df['rating_0_to_50']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Series têm também métodos para calcular quantidades estatísticas comuns, como a média (**mean**), a moda (**mode**), e a mediana (**median**), entre outras. Vejamos qual o valor destas quantidades estatísticas nas reviews: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"\\nMean: {df['reviews.rating'].mean()}\\n\")\n",
    "print(f\"Median: {df['reviews.rating'].median()}\\n\")\n",
    "print(f\"Mode: {df['reviews.rating'].mode()}\")  # retorna uma série, porque pode haver várias modes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos também usar operações mais avançadas na construção de colunas, usando o método **apply**. Podemos passar uma função, e ela será aplicada elemento a elemento. Vamos criar uma coluna que diga se a palavra \"romantic\" está contida em cada review, apenas para reviews que sejam strings (caso contrário teríamos um erro):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def romantic(review):\n",
    "    if type(review) == str :\n",
    "        return (\"romantic\" in review)\n",
    "\n",
    "df['is_romantic'] = df['reviews.text'].apply(romantic)\n",
    "\n",
    "df['is_romantic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para colunas de texto, podemos também aceder a métodos de string e aplicá-los individualmente a cada elemento. Para tal apenas precisar de adicionar **.str** antes do método, e de seguida usá-lo como se estivessemos a user com um único string. Vejamos como obter uma versão \"upper case\" das reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviews.text'].str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra funcionalidade bastante útil é verificar se cada elemento de uma Series é igual a um elemento de uma lista. Podemos fazê-lo através do método **isin**, que devolve uma série com True/False para cada elemento da Series, conforme esteja ou não presente na lista.\n",
    "\n",
    "Vamos usar este étodo para seleccionar todas as reviews dos utilizadores Paula e Ron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usernames = ['Paula', 'Ron']\n",
    "\n",
    "df.loc[\n",
    "    df['reviews.username'].isin(usernames)\n",
    "].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos também contar o número de valores únicos numa coluna, com o método **nunique**. Por exemplo, vejamos quantos utilizadores diferentes há, comparados com o número de reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utilizadores_unicos = df['reviews.username'].nunique()\n",
    "\n",
    "print(f'Há {utilizadores_unicos} utilizadores e {df.shape[0]} reviews.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos obter um array dos valores distintos encontrados numa série com o método **unique** (este método não retorna uma Series, mas sim outro tipo de estrutura, como veremos um pouco mais à frente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviews.username'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método **value_counts** permite combinar estas duas funcionalidades, contando quantas occorrências de cada valor temos numa Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviews.username'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, é importante notar que podemos obter o vector de valores (sem o índice) contido numa Series através do atributo **values**. Estes \"arrays\" de valores, escondido por trás das abstracções Series/DataFrame, são arrays do **Numpy**, uma library de processamento numérico muito utilizada em Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviews.rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['reviews.rating'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza geral dos dados\n",
    "\n",
    "Agora que sabemos aceder aos dados, vamos fazer uma pequena limpeza inicial, para os podermos comçar a trabalhar com maior detalhe.\n",
    "\n",
    "Ao analisar a DataFrame, reparamos que há uma coluna chamada garbage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.garbage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos eliminá-la com o método **drop**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_garbage = df.drop('garbage', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algumas considerações importantes:\n",
    "\n",
    "* temos de espcifiar que a \"label\" da Series que queremos eliminar se encontra ao longo do eixo das colunas (axis=1). Caso contrário estariamos a tentar eliminar uma linha cujo índice fosse \"garbage\" (que neste caso não existe, por isso teríamos um erro);\n",
    "* a operação **drop**, e em geral todas as operações no Pandas, não são executadas \"inplace\", ou seja, a DataFrame original não é modificada. As operações retornam uma DataFrame modificada, que devemos armazenar numa variável. Para realizar uma operação inplace, podemos usar o argument `inplace=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos mudar o nome das colunas com passando um dicionário ao método **rename**. Este dicionário terá como chaves o nome antigo das colunas, e como valor o nome desejado: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomes = {\n",
    "    'categories': 'categorias',\n",
    "    'address': 'morada'\n",
    "}\n",
    "\n",
    "df_renamed = df_no_garbage.rename(columns=nomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_renamed.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar o método replace para substituir certos valores por outros:\n",
    "\n",
    "* na DataFrame inteira, passando um dicionário com pares (valor original, valor de substituição)\n",
    "* separadamente em certas colunas, passando um dicionário de dicionários, em que as chaves de primeiro nível são o nome de cada coluna em que queremos aplicar substituições, e cada subdicionário contém as substituições que desejamos fazer.\n",
    "\n",
    "Vamos substituir as ocorrências de **US** por **EUA** na coluna country, e as ocorrências de **5921 Valencia Cir** por **5921 Val C.** na coluna morada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "substituicoes = {\n",
    "    'country': {\n",
    "        'US': 'EUA',\n",
    "        'SP': 'ES'\n",
    "    },\n",
    "    'morada': {\n",
    "        '5921 Valencia Cir': '5921 Val C.'\n",
    "    }\n",
    "}\n",
    "\n",
    "df_replaced = df_renamed.replace(substituicoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_replaced.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos também querer substituir todos os valores nulos por um determinado valor. Reparamos anteriormente, na informação da DataFrame, que a coluna `reviews.userCity` tem apenas 4164 valores não-nulos. Vamos substituir todos os valores nulos desta coluna pelo string \"desconhecido\" usando o método **fillna**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_replaced['reviews.userCity'] = df_replaced['reviews.userCity'].fillna(\"desconhecido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_replaced['reviews.userCity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por outro lado, podemos eliminar todas as linhas com valores nulos com o método **dropna**. Se aplicarmos este método sobre uma DataFrame, basta a linha ter um elemento nulo para ser eliminada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_replaced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_replaced.dropna().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir o índice \n",
    "\n",
    "Podemos usar uma das nossas colunas como o índice, se tal fizer mais sentido do que usar uma sequência de números. No nosso caso temos a coluna id, que identifica um estabelecimento. Podemos tornar esta coluna no índice da nossa DataFrame, com o método **set_index**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indexed = df_replaced.set_index('id', drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos `drop=True` para não mantermos uma cópia da coluna quando a tornamos no índice.\n",
    "\n",
    "Vamos olhar e aceder à nossa nova DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indexed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indexed.loc['AVwc252WIN2L1WUfpqLP', ['name', 'reviews.username']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da mesma forma que podemos tornar uma coluna no índice, podemos também tornar o índice numa coluna, e criar um índice novo que seja simplesmente dado pelo número da linha. Desta forma fazemos \"reset\" ao indíce (**reset_index**) e voltamos ao estado inicial. Vejamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indexed.reset_index().head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos também ordenar uma DataFrame pelo índice, usando o método **sort_index**. Neste caso, como o índice é um string, o sorting será por ordem alfabética:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df_indexed.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma das utilidades de definir o índice é que facilita operações de join entre duas DataFrames, como iremos ver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinar DataFrames\n",
    "\n",
    "Podemos também querer combinar duas ou mais DataFrames, combinando a informação que estas contém. No nosso caso, queremos integrar a informação do código postal contida num ficheiro separado, na noss DataFrame das reviews. Podemos fazer isto através de um join."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joins\n",
    "\n",
    "O Pandas suporta operações de join entre duas DataFrames. Esta operação permite \"alinhar\" duas DataFrames ao longo do seu índice, e transferir algumas colunas de uma DataFrame para a outra. Podemos ver os vários tipos de joins na seguinte ilustração:\n",
    "\n",
    "<img src=\"images/joins.png\" alt=\"Python\" style=\"width: 600px;\"/>\n",
    "\n",
    "No nosso caso, vamos querer fazer um **LEFT JOIN**, em que a tabela das reviews é a tabela da esquerda. Isto é: queremos manter todas as rows de reviews, e com base no seu índice, ir buscar os códigos postais correspondentes a uma outra tabela (ficando NaN em todas as linhas para as quais não for encontrado um código postal).\n",
    "\n",
    "Vejamos como o podemos fazer. Comecemos por carregar o ficheiro dos códigos postais:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codigos = pd.read_csv('data/hotel-reviews/postal_codes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codigos.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora definir o índice desta tabela para ser o id, que identifica cada review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codigos_indexed = df_codigos.set_index('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que ambas as tabelas estão indexadas de forma semelhante, podemos fazer o join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews_com_codigos = df_indexed.join(\n",
    "    df_codigos_indexed,\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews_com_codigos[['name', 'country', 'postalCode', 'province']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os joins são uma operação extremamente útil no processamento de dados, e é bastante importante praticarmos extensivamente o seu uso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenação\n",
    "\n",
    "Para além de uma concatenação ao longo do eixo das colunas (através do uso de joins) podemos também concatenar ao longo do eixo das linhas, efectivamente adicionando mais linhas a uma DataFrame. Vamos ver como funciona com um exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(index=[1, 2, 3], data={'x': [1, 2, 3], 'y': [1, 2, 3]})\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(index=[4, 5, 6], data={'z': [1, 2, 3], 'y': [4, 5, 6]})\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([df1, df2], sort=True)\n",
    "\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GroupBy - agrupar rows e calcular valores\n",
    "\n",
    "A última operação que vamos aprender é o GroupBy. Esta é uma operação que permite agrupar varias linhas pelo valor de uma ou mais colunas, e depois calcular quantidades em cada um desses grupos (por exemplo: o valor médio de uma certa coluna dentro de cada grupo).\n",
    "\n",
    "Vamos então tentar responder à questão que nos foi proposta: quais as regiões em que as ratings dos hotéis são mais altas? Comecemos por fazer uma análise por país."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos usar o método **groupby** para agrupar a nossa DataFrame por *country*: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupada = df_reviews_com_codigos.groupby('country')\n",
    "\n",
    "df_agrupada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, a operação **groupby** retorna um objecto do tipo **DataFrameGroupBy**. Se tentarmos aceder a uma coluna deste objecto, iremos obter um outro objecto do tipo **SeriesGroupby**.\n",
    "\n",
    "Ambos estes tipos de objectos contêm a informação dos grupos formatos, que pode ser acedida através do atributo **groups**, um dicionário. Neste dicionário, as chaves são os identificadores de cada grupo (neste caso, o país), e os valores são os indíces das linhas que pertencem a cada grupo.\n",
    "\n",
    "Vejamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupada.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupada.groups.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que o único pais nos nossos dados são os EUA, o que torna a anãlisa pouco útil. Vamos antes agrupar os valores por cidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupada_cidade = df_reviews_com_codigos.groupby('city')\n",
    "\n",
    "print(f\"Há {len(df_agrupada_cidade.groups.keys())} cidades.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora obter o valor médio das reviews em cada cidade. Para isto, podemos seleccionar a coluna **reviews.rating** e aplicar o método **mean**, que será calculado grupo a grupo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_por_cidade = df_agrupada_cidade['reviews.rating'].mean()\n",
    "\n",
    "media_por_cidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(media_por_cidade))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que ao aplicarmos a média, foi-nos devolvida uma Series. Este é o ponto essencial da operação de GroupBy:\n",
    "\n",
    "* **Ao aplicarmos uma operação de agregação sobre um objecto GroupBy, vamos obter uma Series com o resultado dessa operação em cada grupo**\n",
    "\n",
    "Uma operação de agregação define-se como uma operação que utiliza todos os elementos do grupo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos também aplicar várias operações de agregação em colunas diferentes, com o método **agg**. Algumas das funções mais comuns podem ser identificadas com o seu nome em formato string (como por exemplo 'min' que calcula o valor mínimo num grupo, 'max' que calcula o maximo, 'mean')...\n",
    "\n",
    "Vejamos como podíamos obter simultaneamente o valor médio das reviews, número de reviews em cada grupo, e o número de utilizadores distintos em cada grupo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operacoes = {\n",
    "    'reviews.rating': ['mean', 'count'],\n",
    "    'reviews.username': ['nunique']\n",
    "}\n",
    "\n",
    "df_final = df_reviews_com_codigos.groupby(\n",
    "    'city'\n",
    ").agg(operacoes)\n",
    "\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta operação de agregação retornou uma DataFrame com multiplos níveis nas colunas (**MultiIndex**). Este é um tema mais avançado e fora do scope deste notebook; por agora, basta sabermos que para aceder a estas colunas, usamos um **tuple** com o nome dos vários níveis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[('reviews.rating', 'mean')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta agregação permite-nos fazer uma análise mais detalhada. Imaginemos que não tinhamos calculado o número de utilizadores em cada grupo. Então, podiam haver certas cidades em que o valor médio das reviews era 5 estrelas (perfeito), mas em que tinha havido apenas uma ou duas reviews.\n",
    "\n",
    "Podemos agora apresentar a nossa recomendação final quanto aos melhores destinos para a empresa direccionar as suas campanhas publicitárias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comecemos por filtrar cidades com menos de 100 reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrada = df_final.loc[\n",
    "    df_final[('reviews.rating', 'count')] >= 100\n",
    "]\n",
    "\n",
    "df_filtrada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E agora, vamos:\n",
    "\n",
    "* ordená-la por ordem decrescente, usando o método **sort_values**, e indicando a coluna de ordenação, assinalando **ascending** = False;\n",
    "* seleccionar o top 5, com o método .iloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5 = df_filtrada.sort_values(\n",
    "    ('reviews.rating', 'mean'),\n",
    "    ascending=False\n",
    ").iloc[0:5]\n",
    "\n",
    "top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decrescente.iloc[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E aqui temos a resposta a pergunta que nos foi colocada. Resta apenas guardar o resultado num ficheiro. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "\n",
    "Podemos exportar as nossas DataFrames para vários tipos de ficheiros, com os métodos **to_<extensão>**.\n",
    "\n",
    "Vamos guardar o resultado como csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5.to_csv('data/hotel-reviews/top5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusão \n",
    "\n",
    "Neste Notebook, aprendemos os básicos de Pandas através de um exemplo de uma tarefa que podia fazer parte do dia a dia de um data scientist. As técnicas aprendidas neste notebook são úteis para vaŕios tipos de problemas, mas para além disso o Pandas tem um grande número de funcionalidades adicionais que não estão presentes neste notebook.\n",
    "\n",
    "Restam algumas considerações finais sobre o \"workflow\" de um Data Scientist:\n",
    "\n",
    "* em geral, os dados que vão encontrar no dia-a-dia podem não ser tão \"limpos\" e directos como os dados que utilizámos aqui. Na verdade, uma grande parte do tempo de um Data Scientist será passado a entender e organizar dados (não vai ser só treinar modelos de machine learning!)\n",
    "* uma boa prática (especialmente) ao utilizar o Pandas é guardar cada transformação dos dados numa nova variável, com um nome explícito, e evitar operações \"inplace\". tentamos seguir este princípio na tarefa deste Notebook. Esta abordagem torna o código mais legível e diminui em geral o número de erros.\n",
    "* a criar DataFrames (ou quaquer outro tipo de estrutura tabular), **evitem incluir informação quantitativa no nome das colunas**. Para compreender este ponto, vejamos um exemplo, com uma DataFrame que inclui dados sobre a percentagem de três grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = {\n",
    "    \"grupo\": ['grupo_1', 'grupo_2', 'grupo_3'],\n",
    "    \"<25\": [33, 31, 39],\n",
    "    \">=25, <50\": [22, 40, 41],\n",
    "    \">=50\": [34, 29, 20]\n",
    "}\n",
    "               \n",
    "df_idades = pd.DataFrame(dados)\n",
    "\n",
    "df_idades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta abordagem é má por duas razões:\n",
    "\n",
    "* primeiro, força-nos a fazer slicing nas linhas e nas colunas para responder a questões numéricas sobre as idades dos grupos;\n",
    "* depois, suponhamos que queriamos contabilizar um novo intervale de idades para apenas um dos grupos - seríamos forçados a criar uma nova coluna que seria NaN para todos os outros grupos.\n",
    "\n",
    "Podemos obter uma versão limpa desta DataFrame com o método **melt**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted = df_idades.melt(\n",
    "    id_vars=['grupo'],\n",
    "    var_name='intervalo de idades', \n",
    "    value_name='contagem'\n",
    ")\n",
    "\n",
    "df_melted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
